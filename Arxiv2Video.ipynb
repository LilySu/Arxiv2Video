{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "72d006d7-cc2a-4de2-a3cb-3a7507a4d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (4.21.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.110.0)\n",
      "Requirement already satisfied: ffmpy in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.12.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.21.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (3.9.15)\n",
      "Requirement already satisfied: packaging in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (2.6.3)\n",
      "Requirement already satisfied: pydub in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio) (0.28.0)\n",
      "Requirement already satisfied: fsspec in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio-client==0.12.0->gradio) (2024.2.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from gradio-client==0.12.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Requirement already satisfied: toolz in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: anyio in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from fastapi->gradio) (0.36.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (1.26.18)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (0.1.9)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (0.0.24)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (0.1.27)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (0.1.10)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (4.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.3 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pypdf) (4.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (4.17.2)\n",
      "Requirement already satisfied: Pillow in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (10.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from pdf2image) (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "!pip install langchain\n",
    "!pip install pypdf\n",
    "!pip install selenium Pillow\n",
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fffae872-e745-4017-a12e-e7c65b714cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://61cc1e9bf3c8b6ff21.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[256], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m         outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m         theme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msky\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 62\u001b[0m \u001b[43miface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts-yt/lib/python3.9/site-packages/gradio/blocks.py:2238\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, _frontend)\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML, Javascript, display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url:\n\u001b[0;32m-> 2238\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnetworking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl_ok\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_url\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2239\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m   2240\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m HTML(\n\u001b[1;32m   2241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<div><iframe src=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m height=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m allow=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoplay; camera; microphone; clipboard-read; clipboard-write;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m frameborder=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m allowfullscreen></iframe></div>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2242\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tts-yt/lib/python3.9/site-packages/gradio/networking.py:255\u001b[0m, in \u001b[0;36murl_ok\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m401\u001b[39m, \u001b[38;5;241m302\u001b[39m):  \u001b[38;5;66;03m# 401 or 302 if auth is set\u001b[39;00m\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mConnectionError\u001b[39;00m, httpx\u001b[38;5;241m.\u001b[39mConnectError):\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import feedparser\n",
    "import requests\n",
    "\n",
    "def download_and_save_pdf(url):\n",
    "    arxiv_id = arxiv_id_from_url(url)\n",
    "    if arxiv_id:\n",
    "        try:\n",
    "            # Make a request to the arXiv API\n",
    "            feed = feedparser.parse(f'http://export.arxiv.org/api/query?id_list={arxiv_id}')\n",
    "\n",
    "            # Check if the response contains entries\n",
    "            if 'entries' in feed:\n",
    "                # Iterate over each entry (paper) in the feed\n",
    "                for entry in feed.entries:\n",
    "                    # Extract the PDF link from the entry\n",
    "                    pdf_link = entry.link.replace('/abs/', '/pdf/') + '.pdf'\n",
    "\n",
    "                    # Download the PDF\n",
    "                    response = requests.get(pdf_link)\n",
    "\n",
    "                    # Save the PDF in the local directory with the name based on the arXiv ID\n",
    "                    with open(f'{arxiv_id}.pdf', 'wb') as pdf_file:\n",
    "                        pdf_file.write(response.content)\n",
    "\n",
    "                    return f\"PDF downloaded and saved as {arxiv_id}.pdf\"\n",
    "\n",
    "            else:\n",
    "                return f\"No entries found for arXiv ID {arxiv_id}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting information: {e}\"\n",
    "    else:\n",
    "        return \"Invalid arXiv PDF URL format. Please enter a valid URL.\"\n",
    "\n",
    "def arxiv_id_from_url(url):\n",
    "    # Extract the arXiv ID from the URL using a regular expression\n",
    "    match = re.search(r'arxiv\\.org/pdf/(\\d+\\.\\d+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "css = \"\"\"\n",
    ".container {\n",
    "    width: 40%;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks(css=css) as demo:\n",
    "    with gr.Column(elem_classes=[\"container\"]):\n",
    "        # elem_classes=[\"container\"],\n",
    "        fn=download_and_save_pdf,\n",
    "        inputs=gr.Textbox(placeholder=\"Enter arXiv PDF URL\"),\n",
    "        outputs=\"text\",\n",
    "        theme=\"sky\"\n",
    "\n",
    "iface.launch(share=True)\n",
    "# https://61cc1e9bf3c8b6ff21.gradio.live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c48f76-70d1-4669-9576-634f0a7283c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e34293-a3ef-44e9-b83d-3bec8df639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from milvus import default_server\n",
    "from pymilvus import connections, utility\n",
    "default_server.start()\n",
    "connections.connect(host=\"127.0.0.1\", port=default_server.listen_port)\n",
    "port=default_server.listen_port\n",
    "host=\"127.0.0.1\"\n",
    "my_uri = \"http://localhost:\" + str(port)\n",
    "print(my_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a87664-91e5-4de8-b27b-4b373264c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize torch settings\n",
    "torch.backends.cudnn.deterministic = True\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "# Load the model from huggingface model hub.\n",
    "# python -m pip install -U angle-emb\n",
    "model_name = \"WhereIsAI/UAE-Large-V1\"\n",
    "encoder = SentenceTransformer(model_name, device=DEVICE)\n",
    "print(type(encoder))\n",
    "print(encoder)\n",
    "\n",
    "# Get the model parameters and save for later.\n",
    "EMBEDDING_DIM = encoder.get_sentence_embedding_dimension()\n",
    "MAX_SEQ_LENGTH_IN_TOKENS = encoder.get_max_seq_length() \n",
    "# # Assume tokens are 3 characters long.\n",
    "# MAX_SEQ_LENGTH = MAX_SEQ_LENGTH_IN_TOKENS * 3\n",
    "# HF_EOS_TOKEN_LENGTH = 1 * 3\n",
    "# Test with 512 sequence length.\n",
    "MAX_SEQ_LENGTH = MAX_SEQ_LENGTH_IN_TOKENS\n",
    "HF_EOS_TOKEN_LENGTH = 1\n",
    "\n",
    "# Inspect model parameters.\n",
    "print(f\"model_name: {model_name}\")\n",
    "print(f\"EMBEDDING_DIM: {EMBEDDING_DIM}\")\n",
    "print(f\"MAX_SEQ_LENGTH: {MAX_SEQ_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3d21a-d77e-44d4-bbfe-596d69400d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "def get_env_variables():\n",
    "    \"\"\"Fetch all necessary configurations from environment variables.\"\"\"\n",
    "    return {\n",
    "        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY')\n",
    "    }\n",
    "\n",
    "load_dotenv()\n",
    "key = get_env_variables()\n",
    "\n",
    "loader = PyPDFLoader(\"1808.05092.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "num_documents = len(docs)\n",
    "print(f\"loaded {num_documents} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d37c0-7970-4fcc-a638-8eda5cd829af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "# Set the Milvus collection name.\n",
    "COLLECTION_NAME = \"MilvusDocs\"\n",
    "\n",
    "# Add custom HNSW search index to the collection.\n",
    "# M = max number graph connections per layer. Large M = denser graph.\n",
    "# Choice of M: 4~64, larger M for larger data and larger embedding lengths.\n",
    "M = 16\n",
    "# efConstruction = num_candidate_nearest_neighbors per layer. \n",
    "# Use Rule of thumb: int. 8~512, efConstruction = M * 2.\n",
    "efConstruction = M * 2\n",
    "# Create the search index for local Milvus server.\n",
    "INDEX_PARAMS = dict({\n",
    "    'M': M,               \n",
    "    \"efConstruction\": efConstruction })\n",
    "index_params = {\n",
    "    \"index_type\": \"HNSW\", \n",
    "    \"metric_type\": \"COSINE\", \n",
    "    \"params\": INDEX_PARAMS\n",
    "    }\n",
    "\n",
    "# Use no-schema Milvus client uses flexible json key:value format.\n",
    "# https://milvus.io/docs/using_milvusclient.md\n",
    "mc = MilvusClient(\n",
    "    uri=my_uri # CLUSTER_ENDPOINT,\n",
    "    # API key or a colon-separated cluster username and password\n",
    "    # token=TOKEN)\n",
    ")\n",
    "\n",
    "# Check if collection already exists, if so drop it.\n",
    "has = utility.has_collection(COLLECTION_NAME)\n",
    "if has:\n",
    "    drop_result = utility.drop_collection(COLLECTION_NAME)\n",
    "    print(f\"Successfully dropped collection: `{COLLECTION_NAME}`\")\n",
    "\n",
    "# Create the collection.\n",
    "mc.create_collection(COLLECTION_NAME, \n",
    "                     EMBEDDING_DIM,\n",
    "                     consistency_level=\"Eventually\", \n",
    "                     auto_id=True,  \n",
    "                     overwrite=True,\n",
    "                     # skip setting params below, if using AUTOINDEX\n",
    "                     params=index_params\n",
    "                    )\n",
    "\n",
    "print(f\"Successfully created collection: `{COLLECTION_NAME}`\")\n",
    "print(mc.describe_collection(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdea0f8-c94c-48cb-8843-cb95b5d08c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import HTMLHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# Use the embedding model parameters.\n",
    "chunk_size = MAX_SEQ_LENGTH - HF_EOS_TOKEN_LENGTH\n",
    "chunk_overlap = np.round(chunk_size * 0.10, 0)\n",
    "print(f\"chunk_size: {chunk_size}, chunk_overlap: {chunk_overlap}\")\n",
    "\n",
    "# Create an instance of the RecursiveCharacterTextSplitter\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "# Split the documents further into smaller, recursive chunks.\n",
    "chunks = child_splitter.split_documents(docs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"chunking time: {end_time - start_time}\")\n",
    "print(f\"split into chunks: {len(chunks)}, type: list of {type(chunks[0])}\") \n",
    "\n",
    "# Inspect a chunk.\n",
    "print()\n",
    "print(\"Looking at a sample chunk...\")\n",
    "print(chunks[0].page_content[:100])\n",
    "print(chunks[0].metadata)\n",
    "\n",
    "# # TODO - Uncomment to print child splits with their associated header metadata.\n",
    "# print()\n",
    "for child in chunks:\n",
    "    print(f\"Content: {child.page_content}\")\n",
    "    print(f\"Metadata: {child.metadata}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e9b0f-4aac-4e99-94d4-82339dc051a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the metadata urls\n",
    "for doc in chunks:\n",
    "    new_url = doc.metadata[\"source\"]\n",
    "    new_url = new_url.replace(\"rtdocs\", \"https:/\")\n",
    "    doc.metadata.update({\"source\": new_url})\n",
    "\n",
    "print(chunks[0].page_content[:100])\n",
    "print(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941d243-361d-43ae-b744-bc938f7e6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert chunks to a list of dictionaries.\n",
    "chunk_list = []\n",
    "for chunk in chunks:\n",
    "\n",
    "    # Generate embeddings using encoder from HuggingFace.\n",
    "    embeddings = torch.tensor(encoder.encode([chunk.page_content]))\n",
    "    # embeddings = F.normalize(embeddings, p=2, dim=1) #use torch\n",
    "    embeddings = np.array(embeddings / np.linalg.norm(embeddings)) #use numpy\n",
    "    converted_values = list(map(np.float32, embeddings))[0]\n",
    "    \n",
    "    # Assemble embedding vector, original text chunk, metadata.\n",
    "    chunk_dict = {\n",
    "        'vector': converted_values,\n",
    "        'chunk': chunk.page_content,\n",
    "        'source': chunk.metadata['source']\n",
    "    }\n",
    "    chunk_list.append(chunk_dict)\n",
    "\n",
    "# Insert data into the Milvus collection.\n",
    "print(\"Start inserting entities\")\n",
    "start_time = time.time()\n",
    "insert_result = mc.insert(\n",
    "    COLLECTION_NAME,\n",
    "    data=chunk_list,\n",
    "    progress_bar=True)\n",
    "end_time = time.time()\n",
    "print(f\"Milvus Client insert time for {len(chunk_list)} vectors: {end_time - start_time} seconds\")\n",
    "\n",
    "# After final entity is inserted, call flush to stop growing segments left in memory.\n",
    "mc.flush(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c84cd-6fa7-48c8-8fbf-a9d4bc687770",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924375bb-2f2e-4452-93f5-6139ddfea016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free option\n",
    "\n",
    "def client_assemble_retrieved_context(retrieved_top_k, metadata_fields=[], num_shot_answers=3):\n",
    "    \"\"\" \n",
    "    For each question, assemble the context and metadata from the retrieved_top_k chunks.\n",
    "    retrieved_top_k: list of dicts\n",
    "    \"\"\"\n",
    "    # Assemble the context as a stuffed string.\n",
    "    distances = []\n",
    "    context = []\n",
    "    context_metadata = []\n",
    "    i = 1\n",
    "    for r in retrieved_top_k[0]:\n",
    "        distances.append(r['distance'])\n",
    "        if i <= num_shot_answers:\n",
    "            if len(metadata_fields) > 0:\n",
    "                metadata = {}\n",
    "                for field in metadata_fields:\n",
    "                    metadata[field] = r['entity'][field]\n",
    "                context_metadata.append(metadata)\n",
    "            context.append(r['entity']['chunk'])\n",
    "        i += 1\n",
    "\n",
    "    # Assemble formatted results in a zipped list.\n",
    "    formatted_results = list(zip(distances, context, context_metadata))\n",
    "    # Return all the things for convenience.\n",
    "    return formatted_results, context, context_metadata\n",
    "\n",
    "SAMPLE_QUESTION = 'what are the parameters of the experiment?'\n",
    "\n",
    "# Embed the question using the same encoder.\n",
    "query_embeddings = encoder.encode([SAMPLE_QUESTION])\n",
    "TOP_K = 3\n",
    "\n",
    "# Return top k results with HNSW index.\n",
    "SEARCH_PARAMS = dict({\n",
    "    # Re-use index param for num_candidate_nearest_neighbors.\n",
    "    \"ef\": INDEX_PARAMS['efConstruction']\n",
    "    })\n",
    "\n",
    "# Define output fields to return.\n",
    "OUTPUT_FIELDS = [\"source\", \"chunk\"]\n",
    "\n",
    "# Embed the question using the same encoder.\n",
    "query_embeddings = encoder.encode([SAMPLE_QUESTION])\n",
    "TOP_K = 3\n",
    "\n",
    "results = mc.search(\n",
    "    COLLECTION_NAME,\n",
    "    data=query_embeddings, \n",
    "    search_params=SEARCH_PARAMS,\n",
    "    output_fields=OUTPUT_FIELDS, \n",
    "    # Milvus can utilize metadata in boolean expressions to filter search.\n",
    "    # filter=\"\",\n",
    "    limit=TOP_K,\n",
    "    consistency_level=\"Eventually\"\n",
    "    )\n",
    "\n",
    "# Assemble `num_shot_answers` retrieved 1st context and context metadata.\n",
    "METADATA_FIELDS = [f for f in OUTPUT_FIELDS if f != 'chunk']\n",
    "# formatted_results, context, context_metadata = _utils.client_assemble_retrieved_context(\n",
    "formatted_results, context, context_metadata = client_assemble_retrieved_context(\n",
    "    results, metadata_fields=METADATA_FIELDS, num_shot_answers=3)\n",
    "print(f\"Length context: {len(context[0])}, Number of contexts: {len(context)}\")\n",
    "\n",
    "# TODO - Uncomment to loop through each context and metadata and print.\n",
    "for i in range(len(context)):\n",
    "    print(f\"Retrieved result #{i+1}\")\n",
    "    print(f\"Context: {context[i][:150]}\")\n",
    "    print(f\"Metadata: {context_metadata[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96fc0f-f2ca-4028-ac2e-670449ae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "LLM_NAME = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0.1\n",
    "\n",
    "llm = ChatOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"), temperature=TEMPERATURE, model_name=LLM_NAME)\n",
    "\n",
    "# Define prompt\n",
    "prompt_template = \"\"\"\n",
    "You will be provided a research paper and your task is to summarize the research paper into a 5 minute video as follows:\n",
    "- Outline the key points of the paper\n",
    "- Edit the outline into a voiceover script for a 5 minute video\n",
    "- Clearly state why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\n",
    "- Do not write any fact which is not present in the paper\n",
    "- The final script should contain 4000 words\n",
    "\n",
    "- First, pretend you are a research scientist who has won accolates for being able to explain expert information to a high-schooler and is giving your dissertation defense.\n",
    "- Write a clearly organized and to-the-point outline summary of the following research:\n",
    "\"{text}\",\n",
    "- The outline should have 3000 words and objectives should be clearly defined for each section of the paper while preserving the specifics address in the technology used or methods tried that have advanced the particular field.\n",
    "- Introduce the research scientists involved and the institutions involved if known.\n",
    "- Every single line in the outline should be in complete sentences, talk with dignity and sophistication. \n",
    "- Use phrases such as \"Our research presents\", \"This paper details the\", do not use words such as realm, or start the sentence with \"In the\"\n",
    "- Assume the audience is asking why and how about the reasoning and logic of the content. \n",
    "- Use present tense and do not use past tense.\n",
    "- Do not use phrases such as \"x has been discussed, x has been highlighted\", be as specific on the details as possible.\n",
    "- Make sure to answer clearly what is the major contribution of this body of work.\n",
    "- The outline should answer to the point and in specific detail why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\n",
    "\n",
    "- After you have produced the outline, next convert each point in the outline to be one or more complete sentences in third person point of view, going into detail especially\n",
    "- regarding the technicalities and key concepts of the research. Make sure that it is absolutely clear in specific detail why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\n",
    "- Assume the role of the editor of the best ranking tv production company in the world. \n",
    "- Format into a script but not screenplay to be broadcasted publicly in a 5 minute production of 4000 words for higher education consumption.\n",
    "- Introduce yourself to assume the role of a third party and do not assume the time of day, do not say good evening you are not the researcher but you represent\n",
    "the researcher in advocating for their work. Provide the narration only, do not format as a screenplay.\n",
    "Spend at least 6 sentences delving deep into the research key findings and evaluation.\n",
    "\n",
    "- Lastly edit the entire script to make sure that it is obviously stated to the video viewer why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "docs = loader.load()\n",
    "print(stuff_chain.run(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6cd601-df22-4b9d-a769-bf44ba964515",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_chain.run(docs)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d55086-5193-4f31-a2ca-3727f28cf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def text_to_speech(text_for_TTS):\n",
    "    ELEVEN_LABS_API_KEY = os.environ.get(\"ELEVEN_LABS_API_KEY\")\n",
    "\n",
    "    CHUNK_SIZE = 1024\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech/bVMeCyTHy58xNoL34h3p\"\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"audio/mpeg\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"xi-api-key\": ELEVEN_LABS_API_KEY\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"text\": text_for_TTS,\n",
    "        \"model_id\": \"eleven_monolingual_v1\",\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 0.5\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Generate a unique filename based on timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f'output_{timestamp}.mp3'\n",
    "\n",
    "        # Save the recording to the unique file\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        print(f\"Recording saved in {filename}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n",
    "text_to_speech(stuff_chain.run(docs)[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95a774-23e0-4083-a274-2914a07a19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def convert_pdf_to_png(pdf_path):\n",
    "    # Create a folder for storing the PNGs\n",
    "    folder_name = os.path.splitext(os.path.basename(pdf_path))[0] + \"_pngs\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Convert each page of the PDF to PNG\n",
    "    images = convert_from_path(pdf_path, output_folder=folder_name)\n",
    "\n",
    "    # Save each image as a separate PNG file\n",
    "    for i, image in enumerate(images):\n",
    "        png_path = os.path.join(folder_name, f\"{folder_name}_page_{i + 1}.png\")\n",
    "        image.save(png_path, \"PNG\")\n",
    "\n",
    "    print(f\"All pages converted and saved in the folder: {folder_name}\")\n",
    "\n",
    "    # Clean up: Delete the .ppm files\n",
    "    for filename in os.listdir(folder_name):\n",
    "        if filename.endswith(\".ppm\"):\n",
    "            ppm_path = os.path.join(folder_name, filename)\n",
    "            os.remove(ppm_path)\n",
    "\n",
    "    print(f\".ppm files deleted in the folder: {folder_name}\")\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = \"1808.05092.pdf\"\n",
    "convert_pdf_to_png(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77433c-a7dc-4bff-993c-811ec5f73eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_image_responses(image_folder):\n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # List to store messages for the OpenAI API call\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"If the image has a diagram or visual, output the file name in a list format and whether it is at the top or bottom of the page?\",\n",
    "        },\n",
    "              ]\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    # Iterate through the images in the folder\n",
    "    for image_filename in os.listdir(image_folder):\n",
    "        if image_filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = f\"{image_folder}/{image_filename}\"  # Replace your_base_url with the actual base URL\n",
    "            # Getting the base64 string\n",
    "            base64_image = encode_image(image_path)\n",
    "            images={\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"low\"},\n",
    "                }\n",
    "            # Append the images structure to the content list in the messages dictionary\n",
    "            messages[0][\"content\"].append(images)\n",
    "\n",
    "    # Make the OpenAI API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=100,\n",
    "    )\n",
    "\n",
    "    # Print the generated responses\n",
    "    for choice in response.choices:\n",
    "        print(choice)\n",
    "\n",
    "# Example usage:\n",
    "image_folder = \"1808.05092_pngs\"\n",
    "generate_image_responses(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47715132-6ce4-4781-8b4d-3934cd3d979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def cut_pngs_in_half(directory_path):\n",
    "    # Ensure the directory path is valid\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Error: Directory '{directory_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Process each file in the directory\n",
    "    for file_name in files:\n",
    "        # Check if the file is a PNG\n",
    "        if file_name.lower().endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "            # Open the image\n",
    "            with Image.open(image_path) as img:\n",
    "                # Get the dimensions of the image\n",
    "                width, height = img.size\n",
    "\n",
    "                # Cut the image in half (top and bottom)\n",
    "                top_half = img.crop((0, 0, width, height // 2))\n",
    "                bottom_half = img.crop((0, height // 2, width, height))\n",
    "\n",
    "                # Save the top and bottom halves with \"_cropped_1\" and \"_cropped_2\" suffixes\n",
    "                top_half.save(os.path.join(directory_path, f\"{os.path.splitext(file_name)[0]}_cropped_1.png\"), 'PNG')\n",
    "                bottom_half.save(os.path.join(directory_path, f\"{os.path.splitext(file_name)[0]}_cropped_2.png\"), 'PNG')\n",
    "\n",
    "                print(f\"Images saved: {file_name}_cropped_1.png (top) and {file_name}_cropped_2.png (bottom)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get user input for the directory path\n",
    "    directory_path = \"1808.05092_pngs\"\n",
    "\n",
    "    # Call the function to cut PNGs in half\n",
    "    cut_pngs_in_half(directory_path)\n",
    "# output_20240310_030318.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ddd04-9f26-474c-b2f4-bad628e41e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoClip, ImageClip, concatenate_videoclips\n",
    "\n",
    "def analyze_mp3_length(mp3_path):\n",
    "    audio = AudioSegment.from_mp3(mp3_path)\n",
    "    return len(audio) / 1000.0  # Length in seconds\n",
    "\n",
    "def fetch_cropped_images(image_directory):\n",
    "    cropped_images = [image for image in os.listdir(image_directory) if image.lower().endswith('.png') and 'cropped' in image.lower()]\n",
    "    return cropped_images\n",
    "\n",
    "def create_video(mp3_path, image_directory, output_path, ffmpeg_executable):\n",
    "    mp3_length = analyze_mp3_length(mp3_path)\n",
    "    cropped_images = fetch_cropped_images(image_directory)\n",
    "\n",
    "    if not cropped_images:\n",
    "        print(\"No cropped images found.\")\n",
    "        return\n",
    "\n",
    "    # Calculate duration per image\n",
    "    duration_per_image = mp3_length / len(cropped_images)\n",
    "\n",
    "    # Create video clips from images\n",
    "    clips = [ImageClip(os.path.join(image_directory, image), duration=duration_per_image) for image in cropped_images]\n",
    "\n",
    "    # Concatenate video clips\n",
    "    video_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "    # Create the 'final_videos' directory if it doesn't exist\n",
    "    final_videos_directory = \"final_videos\"\n",
    "    if not os.path.exists(final_videos_directory):\n",
    "        os.makedirs(final_videos_directory)\n",
    "\n",
    "    # Write the final video\n",
    "    output_path = os.path.join(final_videos_directory, output_path)\n",
    "    video_clip.write_videofile(output_path, codec=\"libx264\", fps=24, ffmpeg_params=[\"-codec\", \"libx264\", \"-preset\", \"ultrafast\", \"-pix_fmt\", \"yuv420p\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    mp3_path = \"output_20240310_030318.mp3\"\n",
    "    image_directory = \"1808.05092_pngs\"\n",
    "    output_path = \"final_videos/1808.05092.mp4\"\n",
    "    ffmpeg_executable = \"/opt/homebrew/bin/ffmpeg\"\n",
    "\n",
    "    create_video(mp3_path, image_directory, output_path, ffmpeg_executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e8c2a511-b91d-424c-bbf5-949c86a9a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/lily/anaconda3/envs/tts-yt/lib/python3.9/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "47c85693-d5b8-4337-bab0-32646c2191d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def analyze_mp3_length(mp3_path):\n",
    "    audio = AudioSegment.from_file(mp3_path)\n",
    "    return len(audio) / 1000.0  # Length in seconds\n",
    "\n",
    "def fetch_cropped_images(image_directory):\n",
    "    cropped_images = [image for image in os.listdir(image_directory) if image.lower().endswith('.png') and 'cropped' in image.lower()]\n",
    "    sorted_images = sorted(cropped_images, key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "    return sorted_images\n",
    "\n",
    "def create_video_with_audio(mp3_path, image_directory):\n",
    "    mp3_length = analyze_mp3_length(mp3_path)\n",
    "    cropped_images = fetch_cropped_images(image_directory)\n",
    "\n",
    "    if not cropped_images:\n",
    "        print(\"No cropped images found.\")\n",
    "        return\n",
    "\n",
    "    # Calculate duration per image\n",
    "    duration_per_image = mp3_length / len(cropped_images)\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_path = \"output_video.mp4\"  # Define output video path\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, 30, (640, 480))  # Adjust resolution as needed\n",
    "\n",
    "    for image in cropped_images:\n",
    "        img = cv2.imread(os.path.join(image_directory, image))\n",
    "        if img is not None:  # Check if image was successfully read\n",
    "            resized_img = cv2.resize(img, (640, 480))\n",
    "            video_writer.write(resized_img)\n",
    "        else:\n",
    "            print(f\"Error reading {image}\")\n",
    "\n",
    "    video_writer.release()\n",
    "\n",
    "    # Add audio to the video\n",
    "    video = cv2.VideoCapture(output_path)\n",
    "    audio = AudioSegment.from_file(mp3_path)\n",
    "    \n",
    "    frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    output_with_audio_path = \"final_video_with_audio.mp4\"\n",
    "    \n",
    "    fourcc_audio = cv2.VideoWriter_fourcc(*'mp4v')  # Change codec to match video codec\n",
    "    audio_writer = cv2.VideoWriter(output_with_audio_path, fourcc_audio, frame_rate, (640, 480))\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        audio_writer.write(frame)\n",
    "    \n",
    "    audio_writer.release()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    mp3_path = \"output_20240310_030318.mp3\"\n",
    "    image_directory = \"1808.05092_pngs\"\n",
    "    \n",
    "    create_video_with_audio(mp3_path, image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc9bd4-00f9-49e2-ba4e-5cb5c6a674bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cab2ea-bf36-48d4-b033-3b7a72672a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
