{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e445fe3-e5e0-4080-9a78-6570bfae7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import feedparser\n",
    "import requests\n",
    "from milvus import default_server\n",
    "from pymilvus import connections, utility\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pdf2image import convert_from_path\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import base64\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "from moviepy.config import change_settings\n",
    "from moviepy.editor import concatenate_videoclips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b35aae-ddeb-4c2b-acbe-4529e441a6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:19530\n"
     ]
    }
   ],
   "source": [
    "change_settings({\"FFMPEG_BINARY\": \"/opt/homebrew/bin/ffmpeg\"})\n",
    "default_server.start()\n",
    "connections.connect(host=\"127.0.0.1\", port=default_server.listen_port)\n",
    "port=default_server.listen_port\n",
    "host=\"127.0.0.1\"\n",
    "my_uri = \"http://localhost:\" + str(port)\n",
    "print(my_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8361215-27c0-4617-bba1-d4e41bcd7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_variables():\n",
    "    \"\"\"Fetch all necessary configurations from environment variables.\"\"\"\n",
    "    return {\n",
    "        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),\n",
    "        'ELEVEN_LABS_API_KEY': os.getenv('ELEVEN_LABS_API_KEY')\n",
    "    }\n",
    "\n",
    "def download_and_save_pdf(url):\n",
    "    arxiv_id = arxiv_id_from_url(url)\n",
    "    if arxiv_id:\n",
    "        try:\n",
    "            # Make a request to the arXiv API\n",
    "            feed = feedparser.parse(f'http://export.arxiv.org/api/query?id_list={arxiv_id}')\n",
    "\n",
    "            # Check if the response contains entries\n",
    "            if 'entries' in feed:\n",
    "                # Iterate over each entry (paper) in the feed\n",
    "                for entry in feed.entries:\n",
    "                    # Extract the PDF link from the entry\n",
    "                    pdf_link = entry.link.replace('/abs/', '/pdf/') + '.pdf'\n",
    "\n",
    "                    # Download the PDF\n",
    "                    response = requests.get(pdf_link)\n",
    "\n",
    "                    # Save the PDF in the local directory with the name based on the arXiv ID\n",
    "                    with open(f'{arxiv_id}.pdf', 'wb') as pdf_file:\n",
    "                        pdf_file.write(response.content)\n",
    "\n",
    "                    print(f\"PDF downloaded and saved as {arxiv_id}.pdf\")\n",
    "                    return arxiv_id\n",
    "\n",
    "            else:\n",
    "                return f\"No entries found for arXiv ID {arxiv_id}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting information: {e}\"\n",
    "    else:\n",
    "        return \"Invalid arXiv PDF URL format. Please enter a valid URL.\"\n",
    "\n",
    "def arxiv_id_from_url(url):\n",
    "    # Extract the arXiv ID from the URL using a regular expression\n",
    "    match = re.search(r'arxiv\\.org/pdf/(\\d+\\.\\d+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"The folder '{folder_name}' has been created.\")\n",
    "    else:\n",
    "        print(f\"The folder '{folder_name}' already exists.\")\n",
    "\n",
    "\n",
    "def text_to_speech(text_for_TTS, arxiv_id):\n",
    "    # Specify the folder name\n",
    "    folder_name = \"audio_voiceover\"\n",
    "    ELEVEN_LABS_API_KEY = os.environ.get(\"ELEVEN_LABS_API_KEY\")\n",
    "\n",
    "    CHUNK_SIZE = 1024\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech/bVMeCyTHy58xNoL34h3p\"\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"audio/mpeg\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"xi-api-key\": ELEVEN_LABS_API_KEY\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"text\": text_for_TTS,\n",
    "        \"model_id\": \"eleven_monolingual_v1\",\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 0.5\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Generate a unique filename based on timestamp\n",
    "        # timestamp = datetime.now().strftime(\"%Y%m%d_%H-%M-%S\")\n",
    "        filename = f'output_{arxiv_id}.mp3'\n",
    "\n",
    "        # Save the recording to the unique file\n",
    "        with open(f\"{folder_name}/{filename}\", 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        print(f\"Recording saved in {folder_name}/{filename}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "def convert_pdf_to_png(pdf_path):\n",
    "    # Create a folder for storing the PNGs\n",
    "    folder_name = os.path.splitext(os.path.basename(pdf_path))[0] + \"_pngs\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Convert each page of the PDF to PNG\n",
    "    images = convert_from_path(pdf_path, output_folder=folder_name)\n",
    "\n",
    "    # Save each image as a separate PNG file\n",
    "    for i, image in enumerate(images):\n",
    "        png_path = os.path.join(folder_name, f\"{folder_name}_page_{i + 1}.png\")\n",
    "        image.save(png_path, \"PNG\")\n",
    "\n",
    "    print(f\"All pages converted and saved in the folder: {folder_name}\")\n",
    "\n",
    "    # Clean up: Delete the .ppm files\n",
    "    for filename in os.listdir(folder_name):\n",
    "        if filename.endswith(\".ppm\"):\n",
    "            ppm_path = os.path.join(folder_name, filename)\n",
    "            os.remove(ppm_path)\n",
    "\n",
    "    print(f\".ppm files deleted in the folder: {folder_name}\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_image_responses(image_folder):\n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # List to store messages for the OpenAI API call\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"If the image has a diagram or visual, output the file name in a list format and whether it is at the top or bottom of the page?\",\n",
    "        },\n",
    "              ]\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    # Iterate through the images in the folder\n",
    "    for image_filename in os.listdir(image_folder):\n",
    "        if image_filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = f\"{image_folder}/{image_filename}\"  # Replace your_base_url with the actual base URL\n",
    "            # Getting the base64 string\n",
    "            base64_image = encode_image(image_path)\n",
    "            images={\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"low\"},\n",
    "                }\n",
    "            # Append the images structure to the content list in the messages dictionary\n",
    "            messages[0][\"content\"].append(images)\n",
    "\n",
    "    # Make the OpenAI API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=100,\n",
    "    )\n",
    "\n",
    "    # Print the generated responses\n",
    "    for choice in response.choices:\n",
    "        print(choice)\n",
    "\n",
    "def cut_pngs_in_half(directory_path):\n",
    "    # Ensure the directory path is valid\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Error: Directory '{directory_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Process each file in the directory\n",
    "    for file_name in files:\n",
    "        # Check if the file is a PNG\n",
    "        if file_name.lower().endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "            # Open the image\n",
    "            with Image.open(image_path) as img:\n",
    "                # Get the dimensions of the image\n",
    "                width, height = img.size\n",
    "\n",
    "                # Cut the image in half (top and bottom)\n",
    "                top_half = img.crop((0, 0, width, height // 2))\n",
    "                bottom_half = img.crop((0, height // 2, width, height))\n",
    "\n",
    "                # Save the top and bottom halves with \"_cropped_1\" and \"_cropped_2\" suffixes\n",
    "                top_half.save(os.path.join(directory_path, f\"{os.path.splitext(file_name)[0]}_cropped_1.png\"), 'PNG')\n",
    "                bottom_half.save(os.path.join(directory_path, f\"{os.path.splitext(file_name)[0]}_cropped_2.png\"), 'PNG')\n",
    "\n",
    "                print(f\"Images saved: {file_name}_cropped_1.png (top) and {file_name}_cropped_2.png (bottom)\")\n",
    "\n",
    "\n",
    "def analyze_mp3_length(mp3_path):\n",
    "    audio = AudioSegment.from_file(mp3_path)\n",
    "    return len(audio) / 1000.0  # Length in seconds\n",
    "\n",
    "def fetch_cropped_images(image_folder):\n",
    "    # List all images in the folder\n",
    "    all_images = os.listdir(image_folder)\n",
    "    \n",
    "    # Identify files to keep (those with the word \"cropped\" in their filenames)\n",
    "    cropped_images = [image for image in all_images if image.lower().endswith('.png') and 'cropped' in image.lower()]\n",
    "    \n",
    "    # Delete files that do not contain the word \"cropped\"\n",
    "    for image in all_images:\n",
    "        if image not in cropped_images:\n",
    "            os.remove(os.path.join(image_folder, image))\n",
    "    \n",
    "    # List the remaining images after deletion\n",
    "    remaining_images = os.listdir(image_folder)\n",
    "    \n",
    "    # Sort the cropped images based on numeric values in their filenames\n",
    "    sorted_images = sorted(remaining_images, key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "    return sorted_images\n",
    "\n",
    "def create_video_with_audio(mp3_path, image_folder, output_path):\n",
    "    # Sort the images in alphanumeric order\n",
    "    image_files = sorted(os.listdir(image_folder))\n",
    "    audio_clip = AudioFileClip(mp3_path)   \n",
    "    \n",
    "    # Calculate the duration of each image based on the total duration of the audio and number of images\n",
    "    image_duration = audio_clip.duration / len(image_files)\n",
    "    \n",
    "    clips = []\n",
    "    \n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        # Load each image and set its duration\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image_clip = ImageSequenceClip([image_path], fps=24).set_duration(image_duration)\n",
    "        \n",
    "        # Add the image clip to the list of clips\n",
    "        clips.append(image_clip)\n",
    "    \n",
    "    # Concatenate the image clips to create the final video\n",
    "    final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_clip = final_clip.set_audio(audio_clip)\n",
    "    \n",
    "    # Write the final video with audio\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", fps=24, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1823e369-6830-456f-996a-34fbcc3b8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt\n",
    "prompt_template = \"\"\"\n",
    "You will be provided a research paper and your task is to summarize the research paper into a 5 minute video as follows:\n",
    "- Outline the key points of the paper\n",
    "- Edit the outline into a voiceover script for a 5 minute video\n",
    "- Clearly state why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\n",
    "- Do not write any fact which is not present in the paper\n",
    "- The final script should contain 4000 words\n",
    "\n",
    "- First, pretend you are a research scientist who has won accolates for being able to explain expert information to a high-schooler and is giving your dissertation defense.\n",
    "- Write a clearly organized and to-the-point outline summary of the following research:\n",
    "\"{text}\",\n",
    "- The outline should have 3000 words and objectives should be clearly defined for each section of the paper while preserving the specifics address in the technology used or methods tried that have advanced the particular field.\n",
    "- Introduce the research scientists involved and the institutions involved if known.\n",
    "- Every single line in the outline should be in complete sentences, talk with dignity and sophistication. \n",
    "- Use phrases such as \"Our research presents\", \"This paper details the\", do not use words such as realm, or start the sentence with \"In the\"\n",
    "- Assume the audience is asking why and how about the reasoning and logic of the content. \n",
    "- Use present tense and do not use past tense.\n",
    "- Do not use phrases such as \"x has been discussed, x has been highlighted\", be as specific on the details as possible.\n",
    "- Make sure to answer clearly what is the major contribution of this body of work.\n",
    "- The outline should answer to the point and in specific detail why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\n",
    "\n",
    "- After you have produced the outline, next convert each point in the outline to be one or more complete sentences in third person point of view, going into detail especially\n",
    "- regarding the technicalities and key concepts of the research. Make sure that it is absolutely clear in specific detail why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\n",
    "- Assume the role of the editor of the best ranking tv production company in the world. \n",
    "- Format into a script but not screenplay to be broadcasted publicly in a 5 minute production of 4000 words for higher education consumption.\n",
    "- Introduce yourself to assume the role of a third party and do not assume the time of day, do not say good evening you are not the researcher but you represent\n",
    "the researcher in advocating for their work. Provide the narration only, do not format as a screenplay.\n",
    "Spend at least 6 sentences delving deep into the research key findings and evaluation.\n",
    "\n",
    "- Lastly edit the entire script to make sure that it is obviously stated to the video viewer why was the research done, what are the technologies that were previously known involved,\n",
    "how is the technique or actions performed advancing the field, what are the key metrics that define the success of the work \n",
    "and what are future directions that lie ahead.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96a0af74-4083-4855-8216-1ac09ce7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url):\n",
    "    load_dotenv()\n",
    "    key = get_env_variables()\n",
    "    \n",
    "    LLM_NAME = \"gpt-3.5-turbo\"\n",
    "    TEMPERATURE = 0.1\n",
    "    \n",
    "    arxiv_id = download_and_save_pdf(url)\n",
    "    \n",
    "    \n",
    "    loader = PyPDFLoader(f\"{arxiv_id}.pdf\")\n",
    "    docs = loader.load()\n",
    "    \n",
    "    num_documents = len(docs)\n",
    "    print(f\"loaded {num_documents} documents\")\n",
    "    \n",
    "    llm = ChatOpenAI(api_key=key[\"OPENAI_API_KEY\"], temperature=TEMPERATURE, model_name=LLM_NAME)\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    # Define StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "    \n",
    "    docs = loader.load()\n",
    "    print(stuff_chain.run(docs))\n",
    "    \n",
    "    # # Specify the folder name\n",
    "    # folder_name = \"audio_voiceover\"\n",
    "    # # Call the function to create the folder\n",
    "    # create_folder(folder_name)\n",
    "    \n",
    "    text_to_speech(stuff_chain.run(docs), arxiv_id)\n",
    "    \n",
    "    # Example usage:\n",
    "    pdf_path = f\"{arxiv_id}.pdf\"\n",
    "    convert_pdf_to_png(pdf_path)\n",
    "    \n",
    "    image_folder = f\"{arxiv_id}_pngs\"\n",
    "    generate_image_responses(image_folder)\n",
    "    \n",
    "    # Call the function to cut PNGs in half\n",
    "    cut_pngs_in_half(image_folder)\n",
    "    \n",
    "    output_path = f\"final_videos/{arxiv_id}.mp4\"  # Update with your desired output path\n",
    "    # Call the function with the provided paths\n",
    "    mp3_path = f\"audio_voiceover/output_{arxiv_id}.mp3\"\n",
    "    \n",
    "    create_video_with_audio(mp3_path, image_folder, output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1a7ee11-32cc-4917-86e5-cf13cfaf8e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded and saved as 2112.12709.pdf\n",
      "loaded 6 documents\n",
      "Hello, I am here to present a groundbreaking research paper titled \"Data-Driven Safety Verification of Stochastic Systems via Barrier Certificates.\" This paper is authored by Ali Salamati, Abolfazl Lavaei, Sadegh Soudjani, and Majid Zamani from various prestigious institutions such as Ludwig-Maximilians-Universität München, ETH Zurich, Newcastle University, and the University of Colorado Boulder.\n",
      "\n",
      "The research paper aims to propose a data-driven approach to formally verify the safety of potentially unknown discrete-time continuous-space stochastic systems. The key technology involved in this research is the use of barrier certificates together with data collected from trajectories of unknown systems. This approach advances the field by providing a safety guarantee over unknown stochastic systems with a priori guaranteed confidence, using a finite number of data points.\n",
      "\n",
      "The main contribution of this work is the development of a data-driven scheme for constructing barrier certificates from data collected from trajectories of unknown systems. By formulating the barrier-based safety problem as a robust convex problem and then solving it as a scenario convex problem, the researchers were able to provide a safety guarantee over unknown stochastic systems with a priori guaranteed confidence.\n",
      "\n",
      "The key metrics that define the success of this work include the construction of a barrier certificate that satisfies safety conditions with a high level of confidence, as well as the application of this approach to an unknown room temperature system to verify the temperature remains within a comfort zone for a finite time horizon with a desired confidence level.\n",
      "\n",
      "Moving forward, future directions for this research include exploring formal controller synthesis for unknown discrete-time stochastic systems using data-driven construction of control barrier certificates. This opens up avenues for further advancements in the field of safety verification for stochastic systems.\n",
      "\n",
      "In conclusion, this research paper presents a novel data-driven approach to safety verification of stochastic systems, offering a promising method for formally analyzing unknown systems with a high level of confidence. The use of barrier certificates and scenario convex problems showcases the potential for advancing the field of safety verification in complex engineering systems.\n",
      "Recording saved in audio_voiceover/output_2112.12709.mp3\n",
      "All pages converted and saved in the folder: 2112.12709_pngs\n",
      ".ppm files deleted in the folder: 2112.12709_pngs\n",
      "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='- Filename: \"Barrier_Certificates_Page_1.png\" - Diagram at the bottom of the page.\\n- Filename: \"Barrier_Certificates_Page_2.png\" - No diagram.\\n- Filename: \"Barrier_Certificates_Page_3.png\" - No diagram.\\n- Filename: \"Barrier_Certificates_Page_4.png\" - Diagram at the top of the page.\\n- Filename: \"Barrier_Certificates_Page_5.png\" - No diagram.\\n- Filename: \"Barrier', role='assistant', function_call=None, tool_calls=None))\n",
      "Images saved: 2112.12709_pngs_page_5.png_cropped_1.png (top) and 2112.12709_pngs_page_5.png_cropped_2.png (bottom)\n",
      "Images saved: 2112.12709_pngs_page_4.png_cropped_1.png (top) and 2112.12709_pngs_page_4.png_cropped_2.png (bottom)\n",
      "Images saved: 2112.12709_pngs_page_6.png_cropped_1.png (top) and 2112.12709_pngs_page_6.png_cropped_2.png (bottom)\n",
      "Images saved: 2112.12709_pngs_page_3.png_cropped_1.png (top) and 2112.12709_pngs_page_3.png_cropped_2.png (bottom)\n",
      "Images saved: 2112.12709_pngs_page_2.png_cropped_1.png (top) and 2112.12709_pngs_page_2.png_cropped_2.png (bottom)\n",
      "Images saved: 2112.12709_pngs_page_1.png_cropped_1.png (top) and 2112.12709_pngs_page_1.png_cropped_2.png (bottom)\n",
      "Moviepy - Building video final_videos/2112.12709.mp4.\n",
      "MoviePy - Writing audio in 2112.12709TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_videos/2112.12709.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_videos/2112.12709.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'video saved to final_videos/2112.12709.mp4'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_url(\"https://arxiv.org/pdf/2112.12709.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c87d92e0-24b3-4dd3-834b-cf42ef7396cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://ec33e8373a47f55d25.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ec33e8373a47f55d25.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded and saved as 1907.09450.pdf\n",
      "loaded 7 documents\n",
      "Good day, esteemed viewers. Today, we delve into a groundbreaking research paper titled \"A New Computation Reduction Based Nonlinear Kalman Filter\" conducted by M. Behvandi, A.A. Suratgar, and M.A. Khosravi from Amirkabir University of Technology in Tehran, Iran. This research introduces a novel algorithm for nonlinear state estimation that significantly reduces computation costs while maintaining high accuracy compared to existing methods like the Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The key innovation lies in propagating the mean and covariance of the state to a 3rd order Taylor series, resulting in improved accuracy and computational efficiency.\n",
      "\n",
      "The primary objective of this research was to address the limitations of existing nonlinear state estimation techniques, particularly the EKF and UKF, which are widely used but can be computationally expensive and numerically unstable. By leveraging deterministic sigma points and a linearized framework, the proposed algorithm reduces the computation cost of the UKF by approximately 50% while maintaining superior accuracy. This advancement is crucial for real-time applications where efficiency and accuracy are paramount.\n",
      "\n",
      "The key metrics that define the success of this work include the reduction in computation cost, the accuracy of state estimation, and the stability of the algorithm. By achieving a significant reduction in computation time without compromising accuracy, the new Kalman filter presents a major advancement in the field of nonlinear state estimation. The research demonstrates the effectiveness of the proposed method through examples and comparisons with existing filters, showcasing its superiority in terms of efficiency and accuracy.\n",
      "\n",
      "Looking ahead, future directions for this research include further optimization of the algorithm for specific applications, exploring the potential for integration with other technologies, and conducting more extensive real-world testing to validate its performance. The ultimate goal is to establish the new Kalman filter as a go-to solution for nonlinear state estimation in various fields, from control systems to image processing, where accuracy and efficiency are critical. This research sets the stage for a new era of state estimation algorithms that prioritize both computational efficiency and accuracy, paving the way for enhanced real-time applications and advancements in the field. Thank you for joining us on this journey of innovation and discovery.\n",
      "Recording saved in audio_voiceover/output_1907.09450.mp3\n",
      "All pages converted and saved in the folder: 1907.09450_pngs\n",
      ".ppm files deleted in the folder: 1907.09450_pngs\n",
      "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is the list of the filenames with the corresponding location on the page:\\n\\n1. \"A New computation reduction based nonlinear Kalman filter - top.jpg\" - Top\\n2. \"A New computation reduction based nonlinear Kalman filter - bottom.jpg\" - Bottom\\n3. \"A New computation reduction based nonlinear Kalman filter - 1.jpg\" - Top\\n4. \"A New computation reduction based nonlinear Kalman filter - 2.jpg\" - Bottom\\n5. \"A New computation reduction', role='assistant', function_call=None, tool_calls=None))\n",
      "Images saved: 1907.09450_pngs_page_4_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_4_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_2_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_6_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_4_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_4_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_2_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_6_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_7_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_2_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_3_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_6_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_7_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_2_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_3_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_6_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_1_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_5_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1.png_cropped_1.png (top) and 1907.09450_pngs_page_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3.png_cropped_1.png (top) and 1907.09450_pngs_page_3.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_1_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_5_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2.png_cropped_1.png (top) and 1907.09450_pngs_page_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6.png_cropped_1.png (top) and 1907.09450_pngs_page_6.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_1_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_5_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7.png_cropped_1.png (top) and 1907.09450_pngs_page_7.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5.png_cropped_1.png (top) and 1907.09450_pngs_page_5.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_1_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_5_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_4.png_cropped_1.png (top) and 1907.09450_pngs_page_4.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_7_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_3_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_7_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_3_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_7_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_3_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_7_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_7_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_3_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_3_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_4_cropped_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_4_cropped_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_6_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_4_cropped_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_4_cropped_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_6_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_6_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_4_cropped_2_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_4_cropped_2_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_1_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5_cropped_2.png_cropped_1.png (top) and 1907.09450_pngs_page_5_cropped_2.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_4_cropped_2_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_4_cropped_2_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_1_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_1_cropped_1.png_cropped_2.png (bottom)\n",
      "Images saved: 1907.09450_pngs_page_5_cropped_1.png_cropped_1.png (top) and 1907.09450_pngs_page_5_cropped_1.png_cropped_2.png (bottom)\n",
      "Moviepy - Building video final_videos/1907.09450.mp4.\n",
      "MoviePy - Writing audio in 1907.09450TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_videos/1907.09450.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  27%|███████                   | 1093/3990 [00:21<01:21, 35.54it/s, now=None]Traceback (most recent call last):\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 136, in write_frame\n",
      "    self.proc.stdin.write(img_array.tobytes())\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/gradio/queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/gradio/route_utils.py\", line 253, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/gradio/blocks.py\", line 1695, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/gradio/blocks.py\", line 1235, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/gradio/utils.py\", line 692, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/qs/72735_yn25sfwrwf0ryfwcb40000gn/T/ipykernel_22971/2787228980.py\", line 50, in process_url\n",
      "    create_video_with_audio(mp3_path, image_folder, output_path)\n",
      "  File \"/var/folders/qs/72735_yn25sfwrwf0ryfwcb40000gn/T/ipykernel_22971/2453905780.py\", line 245, in create_video_with_audio\n",
      "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", fps=24, verbose=False)\n",
      "  File \"<decorator-gen-73>\", line 2, in write_videofile\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/decorators.py\", line 54, in requires_duration\n",
      "    return f(clip, *a, **k)\n",
      "  File \"<decorator-gen-72>\", line 2, in write_videofile\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/decorators.py\", line 135, in use_clip_fps_by_default\n",
      "    return f(clip, *new_a, **new_kw)\n",
      "  File \"<decorator-gen-71>\", line 2, in write_videofile\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/decorators.py\", line 22, in convert_masks_to_RGB\n",
      "    return f(clip, *a, **k)\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/video/VideoClip.py\", line 300, in write_videofile\n",
      "    ffmpeg_write_video(self, filename, fps, codec,\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 228, in ffmpeg_write_video\n",
      "    writer.write_frame(frame)\n",
      "  File \"/Users/lilysu/anaconda3/envs/condaenv/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 180, in write_frame\n",
      "    raise IOError(error)\n",
      "OSError: [Errno 32] Broken pipe\n",
      "\n",
      "MoviePy error: FFMPEG encountered the following error while writing file final_videos/1907.09450.mp4:\n",
      "\n",
      " b''\n",
      "t:  27%|███████                   | 1093/3990 [00:40<01:21, 35.54it/s, now=None]"
     ]
    }
   ],
   "source": [
    "# Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_url,\n",
    "    inputs=gr.Textbox(placeholder=\"Enter arXiv PDF URL\"),\n",
    "    outputs=gr.Video(),\n",
    "    live=True,\n",
    "    theme=\"sky\",\n",
    "    flagging_options=None,  # Disable the flag button\n",
    "    title=\"Arxiv2Video\",\n",
    ")\n",
    "\n",
    "# Add a submit button\n",
    "submit_button = gr.Button()\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e23e133-4b96-4ddb-ab6f-b50851a71a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18507a8-242a-4f68-b551-a7212c325155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
